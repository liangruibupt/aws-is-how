{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with Step Functions\n",
    "\n",
    "Now that we have our data science project built, we want to implement it in a robust and repeteable manner. For this, we are going to deploy the ETL using AWS Glue, and then train and batch transform the input using SageMaker integration with Amazon Step Functions. \n",
    "\n",
    "This notebook is going to guide you thorugh this process step by step.\n",
    "\n",
    "But first you need to create or set your own bucket. SageMaker´s SDK is a good way to start. \n",
    "\n",
    "## 1. Upload to an S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = sagemaker.Session()\n",
    "your_bucket = ses.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-13 04:53:07--  https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/billing/billing_sm.csv\n",
      "Resolving ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)... 52.217.93.44\n",
      "Connecting to ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)|52.217.93.44|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2021-10-13 04:53:07 ERROR 403: Forbidden.\n",
      "\n",
      "--2021-10-13 04:53:07--  https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/reseller/reseller_sm.csv\n",
      "Resolving ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)... 52.217.93.44\n",
      "Connecting to ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)|52.217.93.44|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2021-10-13 04:53:07 ERROR 403: Forbidden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/billing/billing_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/sales-forecast/reseller/reseller_sm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('billing', 'billing_sm.csv')).upload_file('billing_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('reseller', 'reseller_sm.csv')).upload_file('reseller_sm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Glue Crawlers\n",
    "\n",
    "To use this csv information in the context of a Glue ETL, first we have to create a Glue crawler pointing to the location of each file. The crawler will try to figure out the data types of each column. The safest way to do this process is to create one crawler for each table pointing to a different location.\n",
    "\n",
    "Go to the AWS Console.\n",
    "Select under Services AWS Glue.\n",
    "Or follow <a href='https://us-east-1.console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=crawlers'> this link! </a>       \n",
    "    \n",
    "\n",
    "Under crawlers Add Crawler and two crawlers: create one pointing to each S3 location (one to billing and one to reseller)\n",
    "* Crawler Name: Billing - Next\n",
    "* Crawler source type: Data Store - Next\n",
    "* Add a data store: S3, Specific Path in my Account, Navigate to your bucket and your folder Billing - Next\n",
    "* Add another data store: no - Next\n",
    "* Choose an IAM role: create an IAM role billing-crawler-role (if exists, choose the existing) - Next\n",
    "* Frequency: run on demand - Next\n",
    "* Crawler’s output: Add database implementationdb - Next\n",
    "* Finish\n",
    "\n",
    "\n",
    "Tips: \n",
    "- Make sure you name your Glue data base \"implementationdb\" \n",
    "- Make sure to point to the S3 folder containing each file, not the actual file\n",
    "- Make sure to name your db implementationdb\n",
    "- Make sure to create new roles\n",
    "\n",
    "create a new role to run the crawler. Also, don´t forget to run the crawler\n",
    "\n",
    "<img src='img/crawler1.png' style='width:400px' />\n",
    "\n",
    "<img src='img/crawler2.png' style='width:400px' />\n",
    "\n",
    "\n",
    "\n",
    "Let’s add the second crawler:\n",
    "\n",
    "* Crawler Name: Reseller - Next\n",
    "* Crawler source type: Data Store - Next\n",
    "* Add a data store: S3, Specific Path in my Account, Navigate to your bucket and your folder Reseller - Next\n",
    "* Add another data store: no - Next\n",
    "* Choose an IAM role: create an IAM role reseller-crawler-role (if exists, choose the existing) - Next\n",
    "* Frequency: run on demand - Next\n",
    "* Crawlers’s output: Select database implementationdb - Next\n",
    "* Finish\n",
    "\n",
    "\n",
    "Tips:\n",
    "- Use the same database (implementationdb) but create a different role as each crawler need to access a different folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test crawlers on Athena\n",
    "\n",
    "Go to the <a href='https://console.aws.amazon.com/athena/home?region=us-east-1#'> Athena Console </a> and hit Get Started.\n",
    "\n",
    "Under Settings in the top right corner you can configure an output path for your queries. \n",
    "You can use the following value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-710299592439\n"
     ]
    }
   ],
   "source": [
    "print(your_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-646862220717/athena_results/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f's3://{your_bucket}/athena_results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you set a destination for query results, you can preview the tables created by the crawlers.\n",
    "\n",
    "<img src='img/athena1.png' style='width:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Glue Job\n",
    "\n",
    "First of all, you need to create a role to run the Glue Job. For simplicity we are going to build a role that can be assumed by the Glue Service with administrator access. \n",
    "\n",
    "In the <a href='https://console.aws.amazon.com/athena/home?region=us-east-1#'> IAM Console </a>\n",
    "\n",
    "* Under use case select Glue\n",
    "* Under Policies Select Administrator Access\n",
    "* Name your role GlueAdmin and accept.\n",
    "\n",
    "<img src='img/gluerole1.png' style='width:500px'>\n",
    "<img src='img/gluerole2.png' style='width:500px'>\n",
    "<img src='img/gluerole3.png' style='width:500px'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move to the <a href='https://console.aws.amazon.com/glue/home?region=us-east-1#addJob:'> Glue Job Console </a> and author a new job.\n",
    "    \n",
    "\n",
    "* Name: etlandpipeline\n",
    "* Role: Create a role named Glueadmin with AdministratorAccess (this is because we are testing)\n",
    "* Type: Python Shell\n",
    "* Glue version: Python3 (Glue Version 1.0)\n",
    "* Select A New Script Authored By you\n",
    "* Under Maximum Capacity: 1 - Next\n",
    "\n",
    "    \n",
    "Then hit “Save Job and Edit Script”\n",
    "\n",
    "You can use the following script to run your job:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = open('etlandpipeline.py', 'r').read().replace('your_bucket',your_bucket)\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Step Function\n",
    "\n",
    "First you need to create a role that can be assumed by AWS Step Functions and have enough permissions to create and use for inference SageMaker models and run Glue Jobs. \n",
    "First, we are going to create a role that can be assumed by the service Step Functions and then we are going to modify it to add Administrator Access. You can name this role StepFunctionsAdmin\n",
    "\n",
    "\n",
    "<img src='img/iamstep.png' />\n",
    "\n",
    "Tip: In this particular case it can not be done in the same step.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Next go to the <a href='https://console.aws.amazon.com/states/home?region=us-east-1#/statemachines'> Step Functions </a> console and create a new State Machine.\n",
    "\n",
    "* Author with code snippets\n",
    "* Standard\n",
    "\n",
    "\n",
    "In the json place you can use the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "your_role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Comment\": \"Full ML Pipeline\",\n",
      "  \"StartAt\": \"Start Glue Job\",\n",
      "  \"States\": {\n",
      "    \"Start Glue Job\": {\n",
      "      \"Type\": \"Task\",\n",
      "      \"Resource\": \"arn:aws:states:::glue:startJobRun.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"JobName\": \"etlandpipeline\"\n",
      "      },\n",
      "      \"Next\": \"Train model (XGBoost)\"\n",
      "    },\n",
      "    \"Train model (XGBoost)\": {\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"AlgorithmSpecification\": {\n",
      "          \"TrainingImage\": \"811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\",\n",
      "          \"TrainingInputMode\": \"File\"\n",
      "        },\n",
      "        \"OutputDataConfig\": {\n",
      "          \"S3OutputPath\": \"s3://sagemaker-us-east-1-646862220717/models\"\n",
      "        },\n",
      "        \"StoppingCondition\": {\n",
      "          \"MaxRuntimeInSeconds\": 86400\n",
      "        },\n",
      "        \"ResourceConfig\": {\n",
      "          \"InstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.m4.xlarge\",\n",
      "          \"VolumeSizeInGB\": 30\n",
      "        },\n",
      "        \"RoleArn\": \"arn:aws:iam::646862220717:role/TeamRole\",\n",
      "        \"InputDataConfig\": [\n",
      "          {\n",
      "            \"DataSource\": {\n",
      "              \"S3DataSource\": {\n",
      "                \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/train/train.csv\"\n",
      "              }\n",
      "            },\n",
      "            \"ChannelName\": \"train\",\n",
      "            \"ContentType\": \"text/csv\"\n",
      "          },\n",
      "          {\n",
      "            \"DataSource\": {\n",
      "              \"S3DataSource\": {\n",
      "                \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/validation/validation.csv\"\n",
      "              }\n",
      "            },\n",
      "            \"ChannelName\": \"validation\",\n",
      "            \"ContentType\": \"text/csv\"\n",
      "          }\n",
      "        ],\n",
      "        \"HyperParameters\": {\n",
      "          \"objective\": \"reg:linear\",\n",
      "          \"num_round\": \"100\",\n",
      "          \"subsample\": \"0.7\",\n",
      "          \"eval_metric\": \"mae\"\n",
      "        },\n",
      "        \"TrainingJobName.$\": \"$$.Execution.Name\"\n",
      "      },\n",
      "      \"Type\": \"Task\",\n",
      "      \"Next\": \"Save Model\"\n",
      "    },\n",
      "    \"Save Model\": {\n",
      "      \"Parameters\": {\n",
      "        \"PrimaryContainer\": {\n",
      "          \"Image\": \"811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest\",\n",
      "          \"Environment\": {},\n",
      "          \"ModelDataUrl.$\": \"$.ModelArtifacts.S3ModelArtifacts\"\n",
      "        },\n",
      "        \"ExecutionRoleArn\": \"arn:aws:iam::646862220717:role/TeamRole\",\n",
      "        \"ModelName.$\": \"$.TrainingJobName\"\n",
      "      },\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "      \"Type\": \"Task\",\n",
      "      \"Next\": \"Batch transform\"\n",
      "    },\n",
      "    \"Batch transform\": {\n",
      "      \"Type\": \"Task\",\n",
      "      \"Resource\": \"arn:aws:states:::sagemaker:createTransformJob.sync\",\n",
      "      \"Parameters\": {\n",
      "        \"ModelName.$\": \"$$.Execution.Name\",\n",
      "        \"TransformInput\": {\n",
      "          \"CompressionType\": \"None\",\n",
      "          \"ContentType\": \"text/csv\",\n",
      "          \"DataSource\": {\n",
      "            \"S3DataSource\": {\n",
      "              \"S3DataType\": \"S3Prefix\",\n",
      "              \"S3Uri\": \"s3://sagemaker-us-east-1-646862220717/to_predict.csv\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"TransformOutput\": {\n",
      "          \"S3OutputPath\": \"s3://sagemaker-us-east-1-646862220717/predictions\"\n",
      "        },\n",
      "        \"TransformResources\": {\n",
      "          \"InstanceCount\": 1,\n",
      "          \"InstanceType\": \"ml.m4.xlarge\"\n",
      "        },\n",
      "        \"TransformJobName.$\": \"$$.Execution.Name\"\n",
      "      },\n",
      "      \"End\": true\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "definition = open('step_function.json', 'r').read().replace('your_bucket',your_bucket).replace('your_role',your_role)\n",
    "print(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the role that you previously created and then you can create and run your state machine. \n",
    "\n",
    "\n",
    "As you process starts running and moves thorugh each step you will be able to see the process running in each servicés console. \n",
    "\n",
    "Check <a href='https://console.aws.amazon.com/glue/home?region=us-east-1#etl:tab=jobs'> Glue </a> for job logs and\n",
    "<a href='https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs'> SageMaker </a> to see the training job, the model that you created and the batch transform process. \n",
    "\n",
    "After you step function finishes the execution, you should see the graph turning to green:\n",
    "\n",
    "<img src='img/step.png' style='width:500px' />\n",
    "\n",
    "You can inspect your predictions in the predictinos folder on you bucket checking <a href='https://s3.console.aws.amazon.com/s3/home?region=us-east-1'>S3</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
