{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dynamic AI Assistants with Amazon Bedrock Inline Agents\n",
    "\n",
    "Before we dive into creating and using persistent agents, we'll walk through the process of setting up and invoking an inline agent, showcasing its flexibility and power in creating dynamic AI assistants. By following our progressive approach, you will gain a comprehensive understanding of how to use inline agents for various use cases and complexity levels. Throughout a single interactive conversation, we will demonstrate how the agent can be enhanced `on the fly` with new tools and instructions while maintaining context of our ongoing discussion.\n",
    "\n",
    "We'll build a simple Inline Agent with a code interpreter.\n",
    "\n",
    "## What are Inline Agents?\n",
    "\n",
    "[Inline agents](https://docs.aws.amazon.com/bedrock/latest/userguide/agents-create-inline.html) are a powerful feature of Amazon Bedrock that allow developers to create flexible and adaptable AI assistants. \n",
    "\n",
    "Unlike traditional static agents, inline agents can be dynamically configured at runtime, enabling real time adjustments to their behavior, capabilities, and knowledge base.\n",
    "\n",
    "Key features of inline agents include:\n",
    "\n",
    "1. **Dynamic configuration**: Modify the agent's instructions, action groups, and other parameters on the fly.\n",
    "2. **Flexible integration**: Easily incorporate external APIs and services as needed for each interaction.\n",
    "3. **Contextual adaptation**: Adjust the agent's responses based on user roles, preferences, or specific scenarios.\n",
    "\n",
    "## Why Use Inline Agents?\n",
    "\n",
    "Inline agents offer several advantages for building AI applications:\n",
    "\n",
    "1. **Rapid prototyping**: Quickly experiment with different configurations without redeploying your application.\n",
    "2. **Personalization**: Tailor the agent's capabilities to individual users or use cases in real time.\n",
    "3. **Scalability**: Efficiently manage a single agent that can adapt to multiple roles or functions.\n",
    "4. **Cost effectiveness**: Optimize resource usage by dynamically selecting only the necessary tools and knowledge for each interaction.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, make sure that you have:\n",
    "\n",
    "1. An active AWS account with access to Amazon Bedrock.\n",
    "2. Necessary permissions to create and invoke inline agents.\n",
    "3. Be sure to complete additonal prerequisites, visit [Amazon Bedrock Inline Agent prerequisites documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inline-agent-prereq.html) to learn more.\n",
    "\n",
    "### Installing prerequisites\n",
    "Let's begin with installing the required packages. This step is important as you need `boto3` version `1.35.68` or later to use inline agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.38.27)\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.12/site-packages (1.38.27)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# uncomment to install the required python packages\n",
    "%pip install --upgrade boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pprint\n",
    "from termcolor import colored\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "# Runtime Endpoints\n",
    "bedrock_rt_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# To manage session id:\n",
    "random_int = random.randint(1,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Inline Agent\n",
    "\n",
    "Next, we'll set up the basic configuration for our Amazon Bedrock Inline Agent. This includes specifying the foundation model, session management, and basic instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change model id as needed:\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "sessionId = f'custom-session-id-{random_int}'\n",
    "endSession = False\n",
    "enableTrace = True\n",
    "\n",
    "# customize instructions of inline agent:\n",
    "agent_instruction = \"\"\"You are a helpful AI assistant helping Octank Inc employees with their questions and processes. \n",
    "You write short and direct responses while being cheerful. You have access to python coding environment that helps you extend your capabilities.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Inline Agent Invocation\n",
    "\n",
    "Let's start by invoking a simple inline agent with just the foundation model and basic instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare request parameters before invoking inline agent\n",
    "request_params = {\n",
    "    \"instruction\": agent_instruction,\n",
    "    \"foundationModel\": model_id,\n",
    "    \"sessionId\": sessionId,\n",
    "    \"endSession\": endSession,\n",
    "    \"enableTrace\": enableTrace,\n",
    "}\n",
    "\n",
    "# define code interpreter tool\n",
    "code_interpreter_tool = {\n",
    "    \"actionGroupName\": \"UserInputAction\",\n",
    "    \"parentActionGroupSignature\": \"AMAZON.CodeInterpreter\"\n",
    "}\n",
    "\n",
    "# add the tool to request parameter of inline agent\n",
    "request_params[\"actionGroups\"] = [code_interpreter_tool]\n",
    "\n",
    "# enable traces\n",
    "request_params[\"enableTrace\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enter the question you want the inline agent to answer\n",
    "request_params['inputText'] = 'what is the time right now in pacific timezone?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking a simple Inline Agent\n",
    "\n",
    "We'll send a request to the agent asking it to perform a simple calculation or code execution task. This will showcase how the agent can interpret and run code on the fly.\n",
    "\n",
    "To do so, we will use the [InvokeInlineAgent](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_InvokeInlineAgent.html) API via boto3 `bedrock-agent-runtime` client.\n",
    "\n",
    "Our function `invoke_inline_agent_helper` also helps us processing the agent trace request and format it for easier readibility. You do not have to use this function in your system, but it will make it easier to observe the code used by code interpreter, the function invocations and the knowledge base content.\n",
    "\n",
    "We also provide the metrics for the agent invocation time and the input and output tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_inline_agent_helper(client, request_params, trace_level=\"core\"):\n",
    "    _time_before_call = datetime.now()\n",
    "\n",
    "    _agent_resp = client.invoke_inline_agent(\n",
    "        **request_params\n",
    "    )\n",
    "\n",
    "    if request_params[\"enableTrace\"]:\n",
    "        if trace_level == \"all\":\n",
    "            print(f\"invokeAgent API response object: {_agent_resp}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"invokeAgent API request ID: {_agent_resp['ResponseMetadata']['RequestId']}\"\n",
    "            )\n",
    "            session_id = request_params[\"sessionId\"]\n",
    "            print(f\"invokeAgent API session ID: {session_id}\")\n",
    "\n",
    "    # Return error message if invoke was unsuccessful\n",
    "    if _agent_resp[\"ResponseMetadata\"][\"HTTPStatusCode\"] != 200:\n",
    "        _error_message = f\"API Response was not 200: {_agent_resp}\"\n",
    "        if request_params[\"enableTrace\"] and trace_level == \"all\":\n",
    "            print(_error_message)\n",
    "        return _error_message\n",
    "\n",
    "    _total_in_tokens = 0\n",
    "    _total_out_tokens = 0\n",
    "    _total_llm_calls = 0\n",
    "    _orch_step = 0\n",
    "    _sub_step = 0\n",
    "    _trace_truncation_lenght = 300\n",
    "    _time_before_orchestration = datetime.now()\n",
    "\n",
    "    _agent_answer = \"\"\n",
    "    _event_stream = _agent_resp[\"completion\"]\n",
    "\n",
    "    try:\n",
    "        for _event in _event_stream:\n",
    "            _sub_agent_alias_id = None\n",
    "\n",
    "            if \"chunk\" in _event:\n",
    "                _data = _event[\"chunk\"][\"bytes\"]\n",
    "                _agent_answer = _data.decode(\"utf8\")\n",
    "\n",
    "            if \"trace\" in _event and request_params[\"enableTrace\"]:\n",
    "                if \"failureTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    print(\n",
    "                        colored(\n",
    "                            f\"Agent error: {_event['trace']['trace']['failureTrace']['failureReason']}\",\n",
    "                            \"red\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if \"orchestrationTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _orch = _event[\"trace\"][\"trace\"][\"orchestrationTrace\"]\n",
    "\n",
    "                    if trace_level in [\"core\", \"outline\"]:\n",
    "                        if \"rationale\" in _orch:\n",
    "                            _rationale = _orch[\"rationale\"]\n",
    "                            print(colored(f\"{_rationale['text']}\", \"blue\"))\n",
    "\n",
    "                        if \"invocationInput\" in _orch:\n",
    "                            # NOTE: when agent determines invocations should happen in parallel\n",
    "                            # the trace objects for invocation input still come back one at a time.\n",
    "                            _input = _orch[\"invocationInput\"]\n",
    "                            print(_input)\n",
    "\n",
    "                            if \"actionGroupInvocationInput\" in _input:\n",
    "                                if 'function' in _input['actionGroupInvocationInput']:\n",
    "                                    tool = _input['actionGroupInvocationInput']['function']\n",
    "                                elif 'apiPath' in _input['actionGroupInvocationInput']:\n",
    "                                    tool = _input['actionGroupInvocationInput']['apiPath']\n",
    "                                else:\n",
    "                                    tool = 'undefined'\n",
    "                                if trace_level == \"outline\":\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using tool: {tool}\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "                                else:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using tool: {tool} with these inputs:\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "                                    if (\n",
    "                                        len(\n",
    "                                            _input[\"actionGroupInvocationInput\"][\n",
    "                                                \"parameters\"\n",
    "                                            ]\n",
    "                                        )\n",
    "                                        == 1\n",
    "                                    ) and (\n",
    "                                        _input[\"actionGroupInvocationInput\"][\n",
    "                                            \"parameters\"\n",
    "                                        ][0][\"name\"]\n",
    "                                        == \"input_text\"\n",
    "                                    ):\n",
    "                                        print(\n",
    "                                            colored(\n",
    "                                                f\"{_input['actionGroupInvocationInput']['parameters'][0]['value']}\",\n",
    "                                                \"magenta\",\n",
    "                                            )\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        print(\n",
    "                                            colored(\n",
    "                                                f\"{_input['actionGroupInvocationInput']['parameters']}\\n\",\n",
    "                                                \"magenta\",\n",
    "                                            )\n",
    "                                        )\n",
    "\n",
    "                            elif \"codeInterpreterInvocationInput\" in _input:\n",
    "                                if trace_level == \"outline\":\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using code interpreter\", \"magenta\"\n",
    "                                        )\n",
    "                                    )\n",
    "                                else:\n",
    "                                    console = Console()\n",
    "                                    _gen_code = _input[\n",
    "                                        \"codeInterpreterInvocationInput\"\n",
    "                                    ][\"code\"]\n",
    "                                    _code = f\"```python\\n{_gen_code}\\n```\"\n",
    "\n",
    "                                    console.print(\n",
    "                                        Markdown(f\"**Generated code**\\n{_code}\")\n",
    "                                    )\n",
    "\n",
    "                        if \"observation\" in _orch:\n",
    "                            if trace_level == \"core\":\n",
    "                                _output = _orch[\"observation\"]\n",
    "                                if \"actionGroupInvocationOutput\" in _output:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"--tool outputs:\\n{_output['actionGroupInvocationOutput']['text'][0:_trace_truncation_lenght]}...\\n\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                if \"agentCollaboratorInvocationOutput\" in _output:\n",
    "                                    _collab_name = _output[\n",
    "                                        \"agentCollaboratorInvocationOutput\"\n",
    "                                    ][\"agentCollaboratorName\"]\n",
    "                                    _collab_output_text = _output[\n",
    "                                        \"agentCollaboratorInvocationOutput\"\n",
    "                                    ][\"output\"][\"text\"][0:_trace_truncation_lenght]\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"\\n----sub-agent {_collab_name} output text:\\n{_collab_output_text}...\\n\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                if \"finalResponse\" in _output:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Final response:\\n{_output['finalResponse']['text'][0:_trace_truncation_lenght]}...\",\n",
    "                                            \"cyan\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "\n",
    "                    if \"modelInvocationOutput\" in _orch:\n",
    "                        _orch_step += 1\n",
    "                        _sub_step = 0\n",
    "                        print(colored(f\"---- Step {_orch_step} ----\", \"green\"))\n",
    "\n",
    "                        _llm_usage = _orch[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage[\"inputTokens\"]\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "                        _orch_duration = (\n",
    "                            datetime.now() - _time_before_orchestration\n",
    "                        )\n",
    "\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Took {_orch_duration.total_seconds():,.1f}s, using {_in_tokens+_out_tokens} tokens (in: {_in_tokens}, out: {_out_tokens}) to complete prior action, observe, orchestrate.\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        # restart the clock for next step/sub-step\n",
    "                        _time_before_orchestration = datetime.now()\n",
    "\n",
    "                elif \"preProcessingTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _pre = _event[\"trace\"][\"trace\"][\"preProcessingTrace\"]\n",
    "                    if \"modelInvocationOutput\" in _pre:\n",
    "                        _llm_usage = _pre[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage[\"inputTokens\"]\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "\n",
    "                        print(\n",
    "                            colored(\n",
    "                                \"Pre-processing trace, agent came up with an initial plan.\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Used LLM tokens, in: {_in_tokens}, out: {_out_tokens}\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                elif \"postProcessingTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _post = _event[\"trace\"][\"trace\"][\"postProcessingTrace\"]\n",
    "                    if \"modelInvocationOutput\" in _post:\n",
    "                        _llm_usage = _post[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage[\"inputTokens\"]\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "                        print(colored(\"Agent post-processing complete.\", \"yellow\"))\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Used LLM tokens, in: {_in_tokens}, out: {_out_tokens}\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                if trace_level == \"all\":\n",
    "                    print(json.dumps(_event[\"trace\"], indent=2))\n",
    "\n",
    "            if \"files\" in _event.keys() and request_params[\"enableTrace\"]:\n",
    "                console = Console()\n",
    "                files_event = _event[\"files\"]\n",
    "                console.print(Markdown(\"**Files**\"))\n",
    "\n",
    "                files_list = files_event[\"files\"]\n",
    "                for this_file in files_list:\n",
    "                    print(f\"{this_file['name']} ({this_file['type']})\")\n",
    "                    file_bytes = this_file[\"bytes\"]\n",
    "\n",
    "                    # save bytes to file, given the name of file and the bytes\n",
    "                    file_name = os.path.join(\"output\", this_file[\"name\"])\n",
    "                    with open(file_name, \"wb\") as f:\n",
    "                        f.write(file_bytes)\n",
    "\n",
    "        if request_params[\"enableTrace\"]:\n",
    "            duration = datetime.now() - _time_before_call\n",
    "\n",
    "            if trace_level in [\"core\", \"outline\"]:\n",
    "                print(\n",
    "                    colored(\n",
    "                        f\"Agent made a total of {_total_llm_calls} LLM calls, \"\n",
    "                        + f\"using {_total_in_tokens+_total_out_tokens} tokens \"\n",
    "                        + f\"(in: {_total_in_tokens}, out: {_total_out_tokens})\"\n",
    "                        + f\", and took {duration.total_seconds():,.1f} total seconds\",\n",
    "                        \"yellow\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if trace_level == \"all\":\n",
    "                print(f\"Returning agent answer as: {_agent_answer}\")\n",
    "\n",
    "        return _agent_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception while processing input to invokeAgent:\\n\")\n",
    "        input_text = request_params[\"inputText\"]\n",
    "        print(f\"  for input text:\\n{input_text}\\n\")\n",
    "        print(\n",
    "            f\"  request ID: {_agent_resp['ResponseMetadata']['RequestId']}, retries: {_agent_resp['ResponseMetadata']['RetryAttempts']}\\n\"\n",
    "        )\n",
    "        print(f\"Error: {e}\")\n",
    "        raise Exception(\"Unexpected exception: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: 57aab0b4-5156-4037-bde4-97f1449cad71\n",
      "invokeAgent API session ID: custom-session-id-72396\n",
      "\u001b[32m---- Step 1 ----\u001b[0m\n",
      "\u001b[33mTook 1.4s, using 1059 tokens (in: 919, out: 140) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mTo get the current time in the Pacific timezone, I will use the Python datetime module to retrieve the current time and convert it to the Pacific timezone.\u001b[0m\n",
      "{'codeInterpreterInvocationInput': {'code': \"\\nimport datetime\\nimport pytz\\n\\npacific = pytz.timezone('US/Pacific')\\nnow = datetime.datetime.now(pacific)\\nprint(now.strftime('%I:%M %p'))\\n      \"}, 'invocationType': 'ACTION_GROUP_CODE_INTERPRETER', 'traceId': '57aab0b4-5156-4037-bde4-97f1449cad71-0'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Generated code</span>                                                                                                     \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime</span><span style=\"background-color: #272822\">                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pytz</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pacific </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> pytz</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">timezone(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'US/Pacific'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">now </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> datetime</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">datetime</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">now(pacific)</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(now</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">strftime(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'%I:%M %p'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">))</span><span style=\"background-color: #272822\">                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mGenerated code\u001b[0m                                                                                                     \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpytz\u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpacific\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpytz\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtimezone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mUS/Pacific\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdatetime\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpacific\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnow\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstrftime\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m%\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mI:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m%\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mM \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m%\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mp\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m---- Step 2 ----\u001b[0m\n",
      "\u001b[33mTook 3.2s, using 1144 tokens (in: 1124, out: 20) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[36mFinal response:\n",
      "The current time in the Pacific timezone is 2:24 AM....\u001b[0m\n",
      "\u001b[33mAgent made a total of 2 LLM calls, using 2203 tokens (in: 2043, out: 160), and took 4.7 total seconds\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current time in the Pacific timezone is 2:24 AM.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_inline_agent_helper(bedrock_rt_client, request_params, trace_level=\"core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the key aspects of using the Amazon Bedrock Inline Agents API:\n",
    "\n",
    "1. Basic agent invocation\n",
    "\n",
    "For more advance topics such as the following, please take a look at the deep dive [agents workshop](https://catalog.workshops.aws/agents-for-amazon-bedrock/en-US):\n",
    "\n",
    "2. Incorporating knowledge bases\n",
    "3. Adding custom action groups\n",
    "4. Implementing guardrails\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
