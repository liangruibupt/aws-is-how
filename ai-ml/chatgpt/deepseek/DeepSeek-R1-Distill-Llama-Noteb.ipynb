{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170cd66c-9f7f-4db9-9673-31b4d7e9e1fe",
   "metadata": {},
   "source": [
    "# Import DeepSeek-R1-Distill-Llama Models to Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates how to import DeepSeek's distilled Llama models to Amazon Bedrock using Custom Model Import (CMI) feature. We'll use the 8B parameter model as an example, <u>but the same process applies to the 70B variant</u>.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "DeepSeek has released several distilled versions of their models based on Llama architecture. These models maintain strong performance while being more efficient than their larger counterparts. The 8B model we'll use here is derived from Llama 3.1 and has been **optimized for reasoning tasks**.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- An AWS account with access to Amazon Bedrock\n",
    "- Appropriate IAM roles and permissions for Bedrock and Amazon S3, following [the instruction here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-import-iam-role.html)\n",
    "- A S3 bucket prepared to store the custom model\n",
    "- Sufficient local storage space (At least 17GB for 8B and 135GB for 70B models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15844386-cbc9-49c9-8dbe-fcbf2dfab1eb",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Packages\n",
    "\n",
    "First, let's install the necessary Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8e0984-0d83-4e83-8710-8d4870444af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.36.3)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.36.14-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.37.0,>=1.36.14 (from boto3)\n",
      "  Downloading botocore-1.36.14-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.37.0,>=1.36.14->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.37.0,>=1.36.14->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.14->boto3) (1.17.0)\n",
      "Downloading boto3-1.36.14-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.36.14-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m161.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.3\n",
      "    Uninstalling botocore-1.36.3:\n",
      "      Successfully uninstalled botocore-1.36.3\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.36.3\n",
      "    Uninstalling boto3-1.36.3:\n",
      "      Successfully uninstalled boto3-1.36.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.14 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.36.14 botocore-1.36.14\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.27.1)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface_hub 0.27.1\n",
      "    Uninstalling huggingface_hub-0.27.1:\n",
      "      Successfully uninstalled huggingface_hub-0.27.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.28.1\n",
      "Collecting hf_transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting huggingface\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: huggingface, hf_transfer\n",
      "Successfully installed hf_transfer-0.1.9 huggingface-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U huggingface_hub\n",
    "!pip install hf_transfer huggingface huggingface_hub \"huggingface_hub[hf_transfer]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec46496-b12a-407e-8ad5-bf4e60a7bf97",
   "metadata": {},
   "source": [
    "### Step 2: Configure Parameters\n",
    "\n",
    "Update these parameters according to your AWS environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9cd8cb8-d3c0-4e6c-ba58-071cdee2894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameters (please update this part based on your setup)\n",
    "bucket_name = \"sagemaker-us-west-2-710299592439\"\n",
    "s3_prefix = \"DeepSeek-R1-Distill-Llama-8B\" # E.x. DeepSeek-R1-Distill-Llama-8B\n",
    "local_directory = \"DeepSeek-R1-Distill-Llama-8B\" # E.x. DeepSeek-R1-Distill-Llama-8B\n",
    "\n",
    "job_name = 'Deepseek-8B-job-2' # E.x. Deepseek-8B-job\n",
    "imported_model_name = 'DeepSeek-R1-Distill-Llama-8B' # E.x. Deepseek-8B-model\n",
    "role_arn = 'arn:aws:iam::710299592439:role/service-role/AmazonSageMaker-ExecutionRole-20250124T194097' # Please make sure it has sufficient permission as listed in the pre-requisite\n",
    "\n",
    "# Region (currently only 'us-west-2' and 'us-east-1' support CMI with Deepseek-Distilled-Llama models)\n",
    "region_info = 'us-west-2' # You can modify to 'us-east-1' based on your need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffabe2-0c4b-431a-aadb-167f5cb26fa4",
   "metadata": {},
   "source": [
    "### Step 3: Download Model from Hugging Face\n",
    "\n",
    "Download the model files from Hugging Face. \n",
    "\n",
    "- Note that you can also use the 70B model by changing the model_id to \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7789f-958b-4459-a345-67891c5c86ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Downloading the 8B model files may take 2-10 minutes depending on your internet connection speed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc12e1c1-2aec-4fda-9199-a32d95d2e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b419d9656cab4bdf8f41ad013e2f22e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4d0488c51b4edda822cc7073c8ac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000002.safetensors:   0%|          | 0.00/8.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e69b3a01e424d0eadac54d91fd65473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000002.safetensors:   0%|          | 0.00/7.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9166a173c26546d6b1431739cff560b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "figures/benchmark.jpg:   0%|          | 0.00/777k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4c48c9f2e140f7a84c92104f02ff7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba569f5729f4fe7a86c10c3680c2383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/19.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e5d166bfd04685908fc97ecda935ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724b49267a1143b5b529da654588b6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b978043fa5a04834beccb48dc0bebb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7252a0e202114ca69ce087bacec45640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c82fdb0eb746c0ba3951310e6decbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d3851b392140c1bb1a6eddfc224e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/DeepSeek-R1-Distill-Llama-8B'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "hf_model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# Enable hf_transfer for faster downloads\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "# Download using snapshot_download with hf_transfer enabled\n",
    "snapshot_download(repo_id=hf_model_id, local_dir=f\"./{local_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557e7ac-0626-4b9a-ba62-d2207e25cd23",
   "metadata": {},
   "source": [
    "### Step 4: Upload Model to S3\n",
    "\n",
    "Upload the downloaded model files to your S3 bucket\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Uploading the 8B model files normally takes 10-20 minutes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ed56d4-ee79-4378-8a77-105889f840b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 34/34 [02:06<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upload_directory_to_s3(local_directory, bucket_name, s3_prefix):\n",
    "    s3_client = boto3.client('s3')\n",
    "    local_directory = Path(local_directory)\n",
    "    \n",
    "    # Get list of all files first\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            local_path = Path(root) / filename\n",
    "            relative_path = local_path.relative_to(local_directory)\n",
    "            s3_key = f\"{s3_prefix}/{relative_path}\"\n",
    "            all_files.append((local_path, s3_key))\n",
    "    \n",
    "    # Upload with progress bar\n",
    "    for local_path, s3_key in tqdm(all_files, desc=\"Uploading files\"):\n",
    "        try:\n",
    "            s3_client.upload_file(\n",
    "                str(local_path),\n",
    "                bucket_name,\n",
    "                s3_key\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {local_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Upload all files\n",
    "upload_directory_to_s3(local_directory, bucket_name, s3_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3042657-a7e1-4063-abb5-73ea1f8cda80",
   "metadata": {},
   "source": [
    "### Step 5: Create Custom Model Import Job\n",
    "\n",
    "Initialize the import job in Amazon Bedrock\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Creating CMI job for 8B model could take 5-20 minutes to complete.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f898ec5-6123-4647-8852-456045efcada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model import job created with ARN: arn:aws:bedrock:us-west-2:710299592439:model-import-job/8p0mnpfc4yyx\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Bedrock client\n",
    "bedrock = boto3.client('bedrock', region_name=region_info)\n",
    "\n",
    "s3_uri = f's3://{bucket_name}/{s3_prefix}/'\n",
    "\n",
    "# Create the model import job\n",
    "response = bedrock.create_model_import_job(\n",
    "    jobName=job_name,\n",
    "    importedModelName=imported_model_name,\n",
    "    roleArn=role_arn,\n",
    "    modelDataSource={\n",
    "        's3DataSource': {\n",
    "            's3Uri': s3_uri\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "job_Arn = response['jobArn']\n",
    "\n",
    "# Output the job ARN\n",
    "print(f\"Model import job created with ARN: {response['jobArn']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a18c49-e5a9-4706-abe5-f11e1dfa4c3a",
   "metadata": {},
   "source": [
    "### Step 6: Monitor Import Job Status\n",
    "\n",
    "Check the status of your import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4235f3-4136-43a8-b461-f7c4e96e174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# Check CMI job status\n",
    "while True:\n",
    "    response = bedrock.get_model_import_job(jobIdentifier=job_Arn)\n",
    "    status = response['status'].upper()\n",
    "    print(f\"Status: {status}\")\n",
    "    \n",
    "    if status in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)  # Check every 60 seconds\n",
    "\n",
    "# Get the model ID\n",
    "model_id = response['importedModelArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612d199-ffcf-4ffd-803e-b05e1c148f88",
   "metadata": {},
   "source": [
    "### Step 7: Wait for Model Initialization\n",
    "\n",
    "Allow time for the model to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9465e3ed-4cb8-4e9e-9740-3e972fec8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 5mins for cold start \n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319747f-4b8f-41b7-abf2-a046e0a23d51",
   "metadata": {},
   "source": [
    "### Step 8: Model Inference with Proper Tokenization\n",
    "\n",
    "#### Understanding the Tokenization Process\n",
    "When working with DeepSeek models, proper tokenization is crucial for optimal performance. The model expects inputs to follow a specific format defined in its `tokenizer_config.json`. This format ensures the model receives prompts in the same structure it was trained on.\n",
    "\n",
    "#### Key Components\n",
    "1. **Tokenizer**: Uses HuggingFace's AutoTokenizer to properly format inputs\n",
    "2. **Generation Function**: Handles the core interaction with the model\n",
    "3. **Auto-Generate Function**: Manages longer responses that might exceed token limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88862d-930e-4721-84d4-46705c2b7908",
   "metadata": {},
   "source": [
    "#### 8.1 Setting Up the Tokenizer\n",
    "First, we'll initialize the tokenizer and Bedrock runtime client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f995cabd-9148-4ce8-b458-c0921130a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bd283eed9f4af68618a77f8626bc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4abbe019584b6dad2eaacbd629ad60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296d5fde1dc0470e824215b7daf27bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)\n",
    "\n",
    "# Initialize Bedrock Runtime client\n",
    "session = boto3.Session()\n",
    "client = session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region_info,\n",
    "    config=Config(\n",
    "        connect_timeout=300,  # 5 minutes\n",
    "        read_timeout=300,     # 5 minutes\n",
    "        retries={'max_attempts': 3}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a8b29-6110-4874-9c76-264fb89b188e",
   "metadata": {},
   "source": [
    "#### 8.2 Core Generation Function\n",
    "\n",
    "This function handles the basic model interaction with proper tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f07be7-7fa4-4deb-84c8-ec1de9829d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(messages, temperature=0.3, max_tokens=4096, top_p=0.9, continuation=False, max_retries=10):\n",
    "    \"\"\"\n",
    "    Generate response using the model with proper tokenization and retry mechanism\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): List of message dictionaries with 'role' and 'content'\n",
    "        temperature (float): Controls randomness in generation (0.0-1.0)\n",
    "        max_tokens (int): Maximum number of tokens to generate\n",
    "        top_p (float): Nucleus sampling parameter (0.0-1.0)\n",
    "        continuation (bool): Whether this is a continuation of previous generation\n",
    "        max_retries (int): Maximum number of retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        dict: Model response containing generated text and metadata\n",
    "    \"\"\"\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n",
    "                                         add_generation_prompt=not continuation)\n",
    "    \n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                body=json.dumps({\n",
    "                    'prompt': prompt,\n",
    "                    'temperature': temperature,\n",
    "                    'max_gen_len': max_tokens,\n",
    "                    'top_p': top_p\n",
    "                }),\n",
    "                accept='application/json',\n",
    "                contentType='application/json'\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['body'].read().decode('utf-8'))\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            attempt += 1\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(30)\n",
    "    \n",
    "    raise Exception(\"Failed to get response after maximum retries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51f911-7368-4244-8291-11ec18fb031a",
   "metadata": {},
   "source": [
    "#### 8.3 Extended Generation Function\n",
    "\n",
    "The thinking process of the model can become quite extensive, especially when dealing with complex reasoning problems that require step-by-step analysis. This often exceeds the output context length we set for the model. To address this limitation:\n",
    "\n",
    "1. We first attempt to generate a complete response\n",
    "2. If the response is truncated (indicated by stop_reason = \"length\"), we:\n",
    "   - Concatenate the partial response to the original prompt\n",
    "   - Make another API call with `continuation=True`\n",
    "   - This sets `add_generation_prompt=False` in the tokenizer call\n",
    "3. This process continues until we get a complete response\n",
    "\n",
    "This approach ensures we capture the model's complete reasoning process while maintaining coherence throughout the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dfe60b-6fb8-4ade-a40f-52aaf592e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_generate(messages, **kwargs):\n",
    "    \"\"\"\n",
    "    Handle longer responses that exceed token limit\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): List of message dictionaries\n",
    "        **kwargs: Additional parameters for generate function\n",
    "    \n",
    "    Returns:\n",
    "        dict: Enhanced response including thinking process and final answer\n",
    "    \"\"\"\n",
    "    res = generate(messages, **kwargs)\n",
    "    while res[\"stop_reason\"] == \"length\":\n",
    "        for v in messages:\n",
    "            if v.get(\"role\") == \"user\":\n",
    "               v[\"content\"] += res[\"generation\"]\n",
    "        res = generate(messages, **kwargs, continuation=True)\n",
    "\n",
    "    for v in messages:\n",
    "        if v.get(\"role\") == \"user\":\n",
    "           gen = v[\"content\"] + res[\"generation\"]\n",
    "           answer = gen.split(\"</think>\")[-1]\n",
    "           think = gen.split(\"</think>\")[0].split(\"<think>\")[-1]\n",
    "           res = {**res, \"generation\": gen, \"answer\": answer, \"think\": think}\n",
    "           return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15a690-1d6a-4b31-ac67-1975ede304ff",
   "metadata": {},
   "source": [
    "### Usage Examples\n",
    "#### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b874032c-1f2f-483f-81da-62bcdab2adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "<think>\n",
      "First, I need to understand the given information. The company's revenue increased from $10 million to $15 million in 2023. The initial operating costs were $7 million, and these costs increased by 20% in 2023.\n",
      "\n",
      "Next, I'll calculate the new operating costs by applying the 20% increase to the initial cost. So, 20% of $7 million is $1.4 million, and adding that to the original $7 million gives a total operating cost of $8.4 million for 2023.\n",
      "\n",
      "Then, to find the operating margin, I'll subtract the new operating costs from the 2023 revenue. That means $15 million minus $8.4 million equals a $6.6 million operating margin.\n",
      "\n",
      "Finally, to express the operating margin as a percentage, I'll divide the operating margin by the revenue and multiply by 100. So, $6.6 million divided by $15 million equals a 44% operating margin.\n",
      "</think>\n",
      "\n",
      "To calculate the **operating margin** for Company A in 2023, follow these steps:\n",
      "\n",
      "### Given:\n",
      "- **Revenue in 2023:** \\$15 million\n",
      "- **Initial operating costs (2022):** \\$7 million\n",
      "- **Increase in operating costs:** 20%\n",
      "\n",
      "### Step 1: Calculate the new operating costs in 2023.\n",
      "\\[\n",
      "\\text{New Operating Costs} = \\text{Initial Operating Costs} + (\\text{Increase in Operating Costs} \\times \\text{Initial Operating Costs})\n",
      "\\]\n",
      "\\[\n",
      "\\text{New Operating Costs} = \\$7\\,\\text{M} + (0.20 \\times \\$7\\,\\text{M}) = \\$7\\,\\text{M} + \\$1.4\\,\\text{M} = \\$8.4\\,\\text{M}\n",
      "\\]\n",
      "\n",
      "### Step 2: Calculate the operating margin.\n",
      "\\[\n",
      "\\text{Operating Margin} = \\text{Revenue} - \\text{New Operating Costs}\n",
      "\\]\n",
      "\\[\n",
      "\\text{Operating Margin} = \\$15\\,\\text{M} - \\$8.4\\,\\text{M} = \\$6.6\\,\\text{M}\n",
      "\\]\n",
      "\n",
      "### Step 3: Express the operating margin as a percentage.\n",
      "\\[\n",
      "\\text{Operating Margin Percentage} = \\left( \\frac{\\text{Operating Margin}}{\\text{Revenue}} \\right) \\times 100\n",
      "\\]\n",
      "\\[\n",
      "\\text{Operating Margin Percentage} = \\left( \\frac{\\$6.6\\,\\text{M}}{\\$15\\,\\text{M}} \\right) \\times 100 = 44\\%\n",
      "\\]\n",
      "\n",
      "### **Final Answer:**\n",
      "\\[\n",
      "\\boxed{44\\%}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"\"\"Given the following financial data:\n",
    "- Company A's revenue grew from $10M to $15M in 2023\n",
    "- Operating costs increased by 20%\n",
    "- Initial operating costs were $7M\n",
    "\n",
    "Calculate the company's operating margin for 2023. Please reason step by step.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": test_prompt}]\n",
    "response = generate(messages)\n",
    "print(\"Model Response:\")\n",
    "print(response[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634701c-1485-4038-bef3-83dbec966fc8",
   "metadata": {},
   "source": [
    "#### Advanced Usage with Complex Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5586afd6-a4f0-4ee8-bb2f-82a48fb9bc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Thinking Process ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Okay, so I need to help this manufacturing company figure out how many units of Product A and Product B to produce to maximize their profit. Hmm, I think I should start by understanding the problem.\n",
       "\n",
       "First, the company has a manufacturing capacity of 60 hours per week. Product A takes 4 hours each, and Product B takes 3 hours each. So, if I let x be the number of Product A and y be the number of Product B, the total hours used would be 4x + 3y. This total can't exceed 60 hours, so the first constraint is 4x + 3y ≤ 60.\n",
       "\n",
       "Next, there's a storage space constraint. The maximum they can store is 20 units total. So, x + y ≤ 20. That's the second constraint.\n",
       "\n",
       "Profit is another important factor. Product A gives $200 profit each, and B gives $150. So, the profit function would be 200x + 150y, which we want to maximize.\n",
       "\n",
       "Also, there are minimum production requirements: at least 3 units of A and at least 2 units of B. So, x ≥ 3 and y ≥ 2.\n",
       "\n",
       "Alright, so to set up the linear programming model:\n",
       "\n",
       "Maximize Z = 200x + 150y\n",
       "\n",
       "Subject to:\n",
       "4x + 3y ≤ 60\n",
       "x + y ≤ 20\n",
       "x ≥ 3\n",
       "y ≥ 2\n",
       "x, y ≥ 0 (though since x ≥3 and y ≥2, these are redundant)\n",
       "\n",
       "Now, I need to solve this step by step. I think the next step is to graph the feasible region. But since I can't draw here, I'll find the corner points by solving the equations.\n",
       "\n",
       "First, let's find where the lines intersect.\n",
       "\n",
       "1. Intersection of 4x + 3y = 60 and x + y = 20.\n",
       "\n",
       "Let me solve these two equations:\n",
       "\n",
       "From the second equation: y = 20 - x\n",
       "\n",
       "Substitute into the first equation: 4x + 3(20 - x) = 60\n",
       "4x + 60 - 3x = 60\n",
       "x + 60 = 60\n",
       "x = 0\n",
       "\n",
       "So, y = 20 - 0 = 20. But wait, x can't be 0 because of the minimum production requirement. So, this point (0,20) is not feasible.\n",
       "\n",
       "2. Next, find where 4x + 3y = 60 intersects y = 2.\n",
       "\n",
       "If y=2, then 4x + 6 = 60 → 4x=54 → x=13.5. So, point (13.5, 2).\n",
       "\n",
       "But check if x + y ≤20: 13.5 +2=15.5 ≤20, so it's within the constraint.\n",
       "\n",
       "3. Find where x + y =20 intersects y=2. Then x=18. So, point (18,2).\n",
       "\n",
       "4. Now, where does 4x +3y=60 intersect x=3? Let's see, x=3, so 12 +3y=60 → 3y=48 → y=16. So, point (3,16). Check x+y=19, which is ≤20, so okay.\n",
       "\n",
       "5. Also, check where 4x +3y=60 intersects y=2 and x=3. That's point (13.5,2) as above.\n",
       "\n",
       "6. Now, the feasible region is bounded by x=3, y=2, 4x +3y=60, and x+y=20. The corner points are (3,2), (13.5,2), (18,2), and the intersection point of 4x +3y=60 and x + y=20, which was (0,20), but that's not feasible because x must be at least 3. Wait, so maybe I missed a point.\n",
       "\n",
       "Wait, actually, the feasible region is a polygon with vertices at (3,2), (13.5,2), (0,20), and (3,16). But (0,20) is not feasible because x must be at least 3, so the feasible region is actually a polygon with vertices at (3,2), (13.5,2), (3,16). Hmm, no, wait, because 4x +3y=60 and x+y=20 intersect at (0,20), but since x can't be 0, the feasible region is bounded by (3,2), (13.5,2), (3,16), and (18,2). Wait, I'm getting confused.\n",
       "\n",
       "Let me clarify.\n",
       "\n",
       "The constraints are:\n",
       "\n",
       "1. 4x +3y ≤60\n",
       "\n",
       "2. x + y ≤20\n",
       "\n",
       "3. x ≥3\n",
       "\n",
       "4. y ≥2\n",
       "\n",
       "So, the feasible region is the area where all these inequalities overlap.\n",
       "\n",
       "The corner points would be:\n",
       "\n",
       "- (3,2): intersection of x=3 and y=2.\n",
       "\n",
       "- (13.5,2): intersection of x=3 and 4x +3y=60.\n",
       "\n",
       "- (3,16): intersection of x=3 and 4x +3y=60.\n",
       "\n",
       "- (18,2): intersection of y=2 and x + y=20.\n",
       "\n",
       "- (0,20): intersection of x=0 and x + y=20, but x=0 is not allowed because x ≥3.\n",
       "\n",
       "Wait, so the feasible region is a polygon with vertices at (3,2), (13.5,2), (18,2), and (3,16). Because 4x +3y=60 and x + y=20 intersect at (0,20), which is not feasible, so the actual corner points are where the constraints cross within the feasible region.\n",
       "\n",
       "So, the corner points are:\n",
       "\n",
       "1. (3,2)\n",
       "\n",
       "2. (13.5,2)\n",
       "\n",
       "3. (18,2)\n",
       "\n",
       "4. (3,16)\n",
       "\n",
       "Now, I need to evaluate the objective function Z=200x +150y at each of these points.\n",
       "\n",
       "Let me compute Z for each:\n",
       "\n",
       "1. At (3,2): Z=200*3 +150*2=600 +300=900\n",
       "\n",
       "2. At (13.5,2): Z=200*13.5 +150*2=2700 +300=3000\n",
       "\n",
       "3. At (18,2): Z=200*18 +150*2=3600 +300=3900\n",
       "\n",
       "4. At (3,16): Let's check if this point is within the constraints. x + y=19 ≤20, okay. 4x +3y=12 +48=60, which is within the capacity. So Z=200*3 +150*16=600 +2400=3000\n",
       "\n",
       "So, comparing these Z values: 900, 3000, 3900, 3000. The maximum is 3900 at (18,2). So, producing 18 units of A and 2 units of B gives the maximum profit of $3900.\n",
       "\n",
       "But wait, let me double-check the point (18,2). Does it satisfy all constraints?\n",
       "\n",
       "x=18, y=2\n",
       "\n",
       "4x +3y=72 +6=78, which is more than 60. Wait, that's a problem. It exceeds the manufacturing capacity.\n",
       "\n",
       "Oh no, I made a mistake earlier. The point (18,2) comes from x + y=20, but 4x +3y=4*18 +6=72 +6=78, which is way over 60. So, that point is not feasible because it violates the manufacturing constraint.\n",
       "\n",
       "So, I need to correct that. Therefore, the point (18,2) is not in the feasible region. So, the feasible region is actually only up to where 4x +3y=60 intersects x + y=20, but that was at (0,20), which is not allowed. So, the feasible region is bounded by (3,2), (13.5,2), and (3,16). But wait, (3,16) is where 4x +3y=60 and x=3, which is (3,16). Let's check x + y=19, which is okay.\n",
       "\n",
       "So, the feasible region is a polygon with vertices at (3,2), (13.5,2), and (3,16). Now, evaluate Z at these points.\n",
       "\n",
       "At (3,2): 900\n",
       "\n",
       "At (13.5,2): 3000\n",
       "\n",
       "At (3,16): 3000\n",
       "\n",
       "So, the maximum is 3000 at both (13.5,2) and (3,16). Wait, but (3,16) is also a vertex. So, the maximum profit is $3000.\n",
       "\n",
       "But wait, earlier I thought (18,2) was a vertex, but it's not feasible because it violates the manufacturing capacity. So, the maximum profit is $3000.\n",
       "\n",
       "But let me make sure. Maybe I should also check if there's another point where x + y=20 intersects 4x +3y=60, but that was at (0,20), which isn't allowed. So, the feasible region is a triangle with vertices at (3,2), (13.5,2), and (3,16). Therefore, the maximum profit is at (13.5,2) and (3,16), both giving $3000.\n",
       "\n",
       "But wait, let's double-check (3,16):\n",
       "\n",
       "4*3 +3*16=12 +48=60, which is okay.\n",
       "\n",
       "x + y=19, which is within 20.\n",
       "\n",
       "So, yes, both points are feasible.\n",
       "\n",
       "But why does (3,16) give the same profit as (13.5,2)? Because 200*3 +150*16=600 +2400=3000, and 200*13.5 +150*2=2700 +300=3000.\n",
       "\n",
       "So, both points yield the same profit.\n",
       "\n",
       "Therefore, the optimal production is either 13.5 units of A and 2 of B, or 3 of A and 16 of B, both giving $3000 profit.\n",
       "\n",
       "But wait, the problem asks for the optimal production quantities. So, maybe both are optimal. However, since 13.5 is not an integer, they might need to round. But the problem didn't specify integer constraints, so maybe 13.5 is okay. But sometimes in production, you can't produce half units, but the question didn't specify, so I think fractional solutions are acceptable.\n",
       "\n",
       "Now, for sensitivity analysis. Let's see which constraints are binding.\n",
       "\n",
       "The objective function is Z=200x +150y.\n",
       "\n",
       "The constraints are:\n",
       "\n",
       "1. 4x +3y ≤60 (binding at (3,16) and (13.5,2))\n",
       "\n",
       "2. x + y ≤20 (not binding since it's not hit at any vertex)\n",
       "\n",
       "3. x ≥3 (binding at (3,2), (3,16))\n",
       "\n",
       "4. y ≥2 (binding at (3,2), (13.5,2))\n",
       "\n",
       "So, the binding constraints are 4x +3y=60, x=3, and y=2.\n",
       "\n",
       "So, the optimal solution is determined by these three constraints.\n",
       "\n",
       "If we increase the profit of A, say, beyond 200, then x would increase. Similarly, if profit of B increases, y might increase.\n",
       "\n",
       "If manufacturing capacity increases, more units can be produced.\n",
       "\n",
       "If storage space increases beyond 20, more can be produced.\n",
       "\n",
       "If the minimums change, that would affect the feasible region.\n",
       "\n",
       "So, the optimal solution is either (13.5,2) or (3,16), both giving same profit.\n",
       "\n",
       "But to confirm, I think (13.5,2) is more efficient in terms of using more manufacturing hours, but both are valid.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Solution ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "To solve the optimization problem, we first set up the linear programming model and then determine the optimal production quantities that maximize profit while satisfying all constraints.\n",
       "\n",
       "### Step 1: Define the Linear Programming Model\n",
       "\n",
       "**Objective Function:**\n",
       "Maximize profit, which is given by:\n",
       "\\[ Z = 200x + 150y \\]\n",
       "where:\n",
       "- \\( Z \\) = Total profit\n",
       "- \\( x \\) = Number of units of Product A produced\n",
       "- \\( y \\) = Number of units of Product B produced\n",
       "\n",
       "**Constraints:**\n",
       "1. Manufacturing capacity:\n",
       "\\[ 4x + 3y \\leq 60 \\]\n",
       "2. Storage space:\n",
       "\\[ x + y \\leq 20 \\]\n",
       "3. Minimum production:\n",
       "\\[ x \\geq 3 \\]\n",
       "\\[ y \\geq 2 \\]\n",
       "\n",
       "### Step 2: Determine the Feasible Region\n",
       "\n",
       "To find the feasible region, we solve the system of inequalities.\n",
       "\n",
       "1. **Intersection of \\( 4x + 3y = 60 \\) and \\( x + y = 20 \\):**\n",
       "   - Solving these equations:\n",
       "     - From \\( x + y = 20 \\), we get \\( y = 20 - x \\).\n",
       "     - Substitute into \\( 4x + 3(20 - x) = 60 \\):\n",
       "       \\[ 4x + 60 - 3x = 60 \\]\n",
       "       \\[ x = 0 \\]\n",
       "     - Then, \\( y = 20 \\).\n",
       "   - Point: \\( (0, 20) \\) (Not feasible since \\( x \\geq 3 \\)).\n",
       "\n",
       "2. **Intersection of \\( 4x + 3y = 60 \\) and \\( x = 3 \\):**\n",
       "   - Substitute \\( x = 3 \\):\n",
       "     \\[ 12 + 3y = 60 \\]\n",
       "     \\[ y = 16 \\]\n",
       "   - Point: \\( (3, 16) \\)\n",
       "\n",
       "3. **Intersection of \\( 4x + 3y = 60 \\) and \\( y = 2 \\):**\n",
       "   - Substitute \\( y = 2 \\):\n",
       "     \\[ 4x + 6 = 60 \\]\n",
       "     \\[ x = 13.5 \\]\n",
       "   - Point: \\( (13.5, 2) \\)\n",
       "\n",
       "4. **Intersection of \\( x = 3 \\) and \\( y = 2 \\):**\n",
       "   - Point: \\( (3, 2) \\)\n",
       "\n",
       "### Step 3: Identify the Feasible Region\n",
       "\n",
       "The feasible region is a polygon bounded by:\n",
       "- \\( x \\geq 3 \\)\n",
       "- \\( y \\geq 2 \\)\n",
       "- \\( 4x + 3y \\leq 60 \\)\n",
       "- \\( x + y \\leq 20 \\)\n",
       "\n",
       "The feasible region's vertices are:\n",
       "1. \\( (3, 2) \\)\n",
       "2. \\( (13.5, 2) \\)\n",
       "3. \\( (3, 16) \\)\n",
       "\n",
       "### Step 4: Evaluate the Objective Function at Each Vertex\n",
       "\n",
       "1. **At \\( (3, 2) \\):**\n",
       "   \\[ Z = 200(3) + 150(2) = 600 + 300 = 900 \\]\n",
       "\n",
       "2. **At \\( (13.5, 2) \\):**\n",
       "   \\[ Z = 200(13.5) + 150(2) = 2700 + 300 = 3000 \\]\n",
       "\n",
       "3. **At \\( (3, 16) \\):**\n",
       "   \\[ Z = 200(3) + 150(16) = 600 + 2400 = 3000 \\]\n",
       "\n",
       "The maximum profit of \\$3000 occurs at both \\( (13.5, 2) \\) and \\( (3, 16) \\).\n",
       "\n",
       "### Step 5: Verify Constraints\n",
       "\n",
       "Both points satisfy all constraints:\n",
       "- \\( 4(13.5) + 3(2) = 60 \\) and \\( 3 + 16 = 19 \\leq 20 \\)\n",
       "- \\( 4(3) + 3(16) = 60 \\) and \\( 3 + 2 = 5 \\geq 3 \\)\n",
       "\n",
       "### Step 6: Analyze Sensitivity to Changes in Constraints\n",
       "\n",
       "- **Manufacturing Capacity:** If this increases, more units can be produced.\n",
       "- **Storage Space:** If increased, more units can be stored.\n",
       "- **Minimum Production:** Adjusting these affects the lower bounds, potentially changing the optimal solution.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The optimal production quantities are either **13.5 units of Product A and 2 units of Product B** or **3 units of Product A and 16 units of Product B**, both yielding a maximum profit of **\\$3000**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complex_prompt = \"\"\"Solve the following optimization problem:\n",
    "\n",
    "A manufacturing company produces two types of products: A and B. \n",
    "They need to determine the optimal production quantities to maximize profit.\n",
    "\n",
    "Given constraints:\n",
    "1. Manufacturing capacity: 60 hours per week\n",
    "2. Product A takes 4 hours to produce\n",
    "3. Product B takes 3 hours to produce\n",
    "4. Storage space can hold maximum 20 units total\n",
    "5. Profit per unit:\n",
    "   - Product A: $200\n",
    "   - Product B: $150\n",
    "6. Minimum required production:\n",
    "   - At least 3 units of Product A\n",
    "   - At least 2 units of Product B\n",
    "\n",
    "Please:\n",
    "1. Set up the linear programming equations\n",
    "2. Solve step by step\n",
    "3. Verify all constraints are met\n",
    "4. Calculate maximum profit\n",
    "5. Analyze sensitivity to changes in constraints\n",
    "6. Recommend optimal production plan\n",
    "\n",
    "Show all your work and reasoning at each step.\"\"\"\n",
    "\n",
    "# System prompt to encourage detailed mathematical reasoning\n",
    "system_prompt = \"\"\"You are a mathematical optimization expert. \n",
    "Please provide detailed step-by-step solutions showing:\n",
    "- All equations and their development\n",
    "- Each calculation step\n",
    "- Verification of constraints\n",
    "- Clear reasoning for each decision\n",
    "- Visual representations where helpful\"\"\"\n",
    "\n",
    "# Run the analysis with auto_generate\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": complex_prompt}\n",
    "]\n",
    "\n",
    "response = auto_generate(messages, temperature=0.7, max_tokens=4096, top_p=0.9)\n",
    "\n",
    "# Display the response\n",
    "print(\"\\n=== Thinking Process ===\")\n",
    "display(Markdown(response[\"think\"]))\n",
    "print(\"\\n=== Solution ===\")\n",
    "display(Markdown(response[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2490a27-95df-480f-a583-4f3188afb148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "<think>\n",
      "嗯，我现在要分析中国汽车企业出海的成功要素和挑战，还要给出解决建议。首先，我得先了解出海的基本概念。出海指的是中国企业将产品或服务出口到国际市场，尤其是发达国家和新兴市场。对于汽车企业来说，这可能意味着要进入全球的汽车市场，面对不同的法规、文化和竞争。\n",
      "\n",
      "首先，品牌影响力是一个关键因素。中国的汽车品牌在国内市场占据很大份额，比如大众、丰田、本田等，但在国际市场上可能不太有知名度。所以，品牌推广和国际化是必须的。比如，特斯拉在中国的成功是因为品牌价值和技术的结合。中国企业需要投资品牌建设，可能需要与国际知名品牌合作或者进行广告宣传，提升全球知名度。\n",
      "\n",
      "接下来是研发能力。汽车行业技术更新换代很快，发达国家的汽车企业在技术上有很强的研发能力。中国企业如果想在国际市场上竞争，必须有自己的技术突破或者与国际合作，否则可能会被挤出局面。比如，中国的比亚迪在电动汽车领域有很强的研发能力，通过自主创新和技术突破，提升了国际竞争力。\n",
      "\n",
      "然后是质量和安全标准。国际市场对产品质量和安全性有严格的要求，中国企业需要符合欧洲、美国等市场的标准。这可能需要投资质量控制体系，建立国际化的生产和检测流程，确保产品符合各国法规。\n",
      "\n",
      "法律和法规也是一个大问题。每个国家有不同的法规，中国企业需要了解并遵守这些法规，可能需要雇佣国际化的法律团队，或者与当地企业合作，确保合规性。\n",
      "\n",
      "文化差异方面，消费者习惯、语言、商业习惯等都不同。中国企业需要进行市场调研，了解目标市场的需求，调整产品和营销策略，才能成功进入。\n",
      "\n",
      "供应链管理也是关键。国际供应链复杂，涉及多个国家和地区，中国企业需要建立稳定的供应链，确保原材料供应和生产流程的顺畅。同时，可能需要与国际供应商合作，优化供应链管理。\n",
      "\n",
      "竞争优势方面，价格优势可能不适用，因为发达国家消费者更看重品牌和质量。中国企业需要通过技术创新和差异化竞争来保持优势，比如特斯拉在电动汽车领域的技术突破。\n",
      "\n",
      "政府支持也很重要。政府可以提供税收优惠、融资支持和贸易保护，这些都有助于企业国际化。同时，企业需要利用这些政策，制定长远战略。\n",
      "\n",
      "最后，进入新兴市场可能更容易，比如东南亚和东欧，这些市场增长快，竞争压力小，适合中国企业作为起点，积累经验和资源。\n",
      "\n",
      "总结一下，成功要素包括品牌建设、技术研发、质量管理、法律合规、文化适应、供应链优化、竞争优势和政府支持。挑战包括品牌认知度、技术差距、质量标准、法律法规、文化差异、供应链管理和竞争压力。建议包括品牌推广、技术研发投入、质量体系建设、法律合规、市场调研、供应链优化、差异化竞争和利用政府政策。\n",
      "\n",
      "在思考过程中，我可能遗漏了一些方面，比如市场进入的选择是否还应该考虑其他因素，比如经济状况、政治稳定性等。此外，如何具体实施这些建议也很重要，比如品牌推广的具体策略，技术研发的投入规模，质量管理的具体措施等。可能需要更详细地分析每个要素的具体实施步骤和案例。\n",
      "</think>\n",
      "\n",
      "中国汽车企业出海面临的挑战与成功要素及建议\n",
      "\n",
      "一、成功要素\n",
      "\n",
      "1. **品牌影响力**\n",
      "   - **国际化推广**：通过广告、赞助等方式提升全球知名度。\n",
      "   - **品牌合作**：与国际知名品牌合作或进行跨国并购，借助其品牌价值。\n",
      "\n",
      "2. **技术研发能力**\n",
      "   - **自主创新**：加大研发投入，提升核心技术水平。\n",
      "   - **国际合作**：与国际领先企业合作，引进技术和管理经验。\n",
      "\n",
      "3. **质量与安全标准**\n",
      "   - **质量体系建设**：建立国际化的质量管理体系，确保符合各国标准。\n",
      "   - **安全性能提升**：投资研发安全技术，确保产品符合国际安全法规。\n",
      "\n",
      "4. **法律与合规**\n",
      "   - **法规遵守**：了解并遵守目标市场的法律法规。\n",
      "   - **法律团队建设**：组建国际化法律团队，确保合规性。\n",
      "\n",
      "5. **文化适应**\n",
      "   - **市场调研**：深入了解目标市场需求和文化习惯。\n",
      "   - **本地化策略**：调整产品和营销策略以适应当地文化。\n",
      "\n",
      "6. **供应链管理**\n",
      "   - **供应链优化**：建立稳定的全球供应链，确保原材料供应和生产流程。\n",
      "   - **国际合作**：与国际供应商合作，优化供应链管理。\n",
      "\n",
      "7. **竞争优势**\n",
      "   - **技术创新**：通过技术差异化，提升产品竞争力。\n",
      "   - **定价策略**：制定适合国际市场的定价策略，平衡价格和利润。\n",
      "\n",
      "8. **政府支持**\n",
      "   - **政策利用**：利用政府提供的税收优惠和融资支持。\n",
      "   - **战略规划**：制定长远国际化战略，确保资源和能力积累。\n",
      "\n",
      "二、挑战\n",
      "\n",
      "1. **品牌认知度低**\n",
      "   - **市场进入壁垒**：国际市场对中国品牌认知度低，需进行品牌推广。\n",
      "\n",
      "2. **技术差距**\n",
      "   - **技术竞争压力**：国际市场技术领先度高，需加大研发投入。\n",
      "\n",
      "3. **质量与安全标准**\n",
      "   - **合规难度**：需投入大量资源确保产品符合各国标准。\n",
      "\n",
      "4. **法律法规复杂**\n",
      "   - **合规成本高**：需投入人力和财力确保合规性。\n",
      "\n",
      "5. **文化差异**\n",
      "   - **市场适应难度**：需深入研究不同市场的文化和消费习惯。\n",
      "\n",
      "6. **供应链管理**\n",
      "   - **风险管理**：应对供应链中断和成本波动。\n",
      "\n",
      "7. **竞争压力**\n",
      "   - **市场竞争激烈**：需应对国际品牌和本土化竞争。\n",
      "\n",
      "三、建议\n",
      "\n",
      "1. **品牌推广**\n",
      "   - 制定长期品牌战略，进行跨文化营销，建立品牌故事和价值观。\n",
      "\n",
      "2. **技术研发投入**\n",
      "   - 加大研发投入，重点突破核心技术，提升国际竞争力。\n",
      "\n",
      "3. **质量体系建设**\n",
      "   - 建立国际化质量管理体系，进行定期质量检查和认证。\n",
      "\n",
      "4. **法律合规**\n",
      "   - 聘用国际化团队，制定合规管理流程，确保合规性。\n",
      "\n",
      "5. **市场调研与策略**\n",
      "   - 进行深入市场调研，制定差异化策略，满足当地需求。\n",
      "\n",
      "6. **供应链优化**\n",
      "   - 建立多元化供应链，分散风险，确保供应稳定。\n",
      "\n",
      "7. **差异化竞争**\n",
      "   - 强化技术研发，提供创新产品，提升市场竞争力。\n",
      "\n",
      "8. **政府政策利用**\n",
      "   - 制定详细的国际化战略，利用政策支持，优化资源配置。\n",
      "\n",
      "通过以上分析，中国汽车企业可以系统地应对出海挑战，实现国际化发展。\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"\"\"中国汽车企业出海的成功要素和挑战有哪些？给出一些建议解决挑战. 请给出一步一步的思考过程.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": test_prompt}]\n",
    "response = generate(messages)\n",
    "print(\"Model Response:\")\n",
    "print(response[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24455a7f-89eb-4538-aadd-784ab1a817d7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the end-to-end process of importing DeepSeek's distilled Llama models to Amazon Bedrock using Custom Model Import (CMI). Starting from downloading the model from HuggingFace, through preparing and uploading files to S3, to creating a CMI job and performing inference, we've covered the essential steps to get your DeepSeek distilled Llama models running on Amazon Bedrock.\n",
    "\n",
    "\n",
    "While we've used the DeepSeek-R1-Distill-Llama-8B model in this example, the same process applies to other variants including the 70B model. For more information about Custom Model Import and its features, refer to the [Amazon Bedrock documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4562d45-7a4d-4954-b144-053b758b4a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
