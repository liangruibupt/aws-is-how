{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af90a9b-6479-4c13-9081-d19bffa64dd0",
   "metadata": {},
   "source": [
    "### 03_Creating Multimodal RAG using Amazon Managed Knowledge Bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a537a-b960-49fb-907d-5188e2fb5155",
   "metadata": {},
   "source": [
    "Knowledge Bases for Amazon Bedrock leverage Retrieval Augmented Generation (RAG), a technique that harnesses customer data stores to enhance responses generated by foundation models. Knowledge bases allow agents to access existing customer data repositories without extensive administrator overhead. To connect a knowledge base to your data, you specify an S3 bucket as the data source. By employing knowledge bases, applications gain enriched contextual information, streamlining development through a fully-managed RAG solution. This level of abstraction accelerates time-to-market by minimizing the effort of incorporating your data into agent functionality and it optimizes cost by negating the necessity for continuous model retraining to leverage private data.\n",
    "Knowledge Base Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b653e-749f-4d27-b11f-4367a87703d9",
   "metadata": {},
   "source": [
    "### Use Case Description\n",
    "\n",
    "We will imagine that we are a Hotel Booking Assistant who helps user with some relevent information abotu the hotel such as finding where the Casino is, to what has been the performance of the hotel in certain quarter based on financial reports to basic room and hotel fare info.\n",
    "\n",
    "For this we would need a RAG System that has these relevent information about a particular hotel. For this excersise we will assume we are ABC Hotel and we will laod some documents which have some information about the hotel. This information will include not just text but also other charts, graph information. \n",
    "\n",
    "\n",
    "### Architecture Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d60be-20c8-40fe-a6c5-e297337dc372",
   "metadata": {},
   "source": [
    "![./images/RAG-diagram.gif](images/RAG-diagram.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00471-2764-453f-bf46-a6bb844f6890",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1. Create the KB Setup\n",
    "\n",
    "**Step 1:** Navigate to the [Amazon Bedrock > Knowledge base > Create knowledge](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/knowledge-bases/create-knowledge-base) base console as shown:\n",
    "\n",
    "![images/kb/kb_starter.png](images/kb/kb_starter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40313fb-027f-41b8-bb2e-1d2de12cde07",
   "metadata": {},
   "source": [
    "**Step 2**: Next, lets select Create Knowledge Base > Knowledge Base with Vector Store "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489b830-f814-4730-a960-09e5ce71b3ed",
   "metadata": {},
   "source": [
    "**Step 3**:Next, lets provide knowledge base details such as KB name, Description etc.\n",
    "\n",
    "In below illustration, we are giving \n",
    "- **KB Name**: `knowledge-base-hotel-info` and feel free to put some relevent description\n",
    "- **IAM Role**: Let KB create an IAM role with all needed permissions.\n",
    "- **DataSource**: Next we choose S3 as our Data source, where we will add some menus to use as RAG data source later in the notebook.\n",
    "![images/kb/kb_id_iam_role.png](images/kb/kb_id_iam_role.png)\n",
    "\n",
    "![images/kb/ds_id.png](images/kb/ds_id.png)\n",
    "\n",
    "For self-hosted workshop, you need to create 2 S3 buckets, you can call them `mmu-workshop-********` and `mmu-workshop-tmp-********`\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note: S3 URI for Data Source</b>- ⚠️ For s3 location for Data Source choose the bucket where you will store the multimodal pdf files. If you are using in workshop you should see a bucket with similar name mmu-workshop-********  and create a partition in there to seperate our data such as `mm-data`\n",
    "So our overall S3 URI becomes like\n",
    "\n",
    "    \n",
    "  `s3://mmu-workshop-********/mm-data`\n",
    "<br>\n",
    "<b>Note: S3 URI for Multimodal Storage</b>- ⚠️ For s3 location for Multimodal Storage(we will show this below) we will create a seperate bucket where the parsed images will be stored. If you are using in workshop you should see a bucket with similar name - mmu-workshop-tmp-********\n",
    "So our overall S3 URI becomes like\n",
    "\n",
    "    \n",
    "  `s3://mmu-workshop-tmp-********`\n",
    "</div>\n",
    "\n",
    "\n",
    "To get our KB stood up. For ref please look at the screenshot attached.\n",
    "\n",
    "![images/kb/kb_fill_in.png](images/kb/kb_fill_in.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894fa26-01c3-4a6e-88e6-41738258e2a9",
   "metadata": {},
   "source": [
    "**Step 4**: **Configure Data Source**\n",
    "Now, lets configure the data source(S3, in this case) for this to happen we need to provide details as described below\n",
    "- **S3 Destination**: The S3 URI where our Multimodal Files are located\n",
    "- For **Parsing Strategy** we will choose _\"**FM Parsing with Claude Haiku 3**\"_- This means that sonent would be used to parse the multimodal content and summarize the images before passing it to generator model, where we will be using Amazon Nova.\n",
    "- We will also show how to use **Bedrock Data Automation as a parser** to fully manage the experience of preprocessing multimodal files\n",
    "\n",
    "![images/kb/kb_configure2.png](images/kb/kb_configure2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6537b-ca09-46cb-8fa8-ba6271077623",
   "metadata": {},
   "source": [
    "**Step 5: Select Embedding Model and Configure Vector Store**\n",
    "\n",
    "- Next, we will select the embedding models to create the vector representation of the multimodal datasets and we will choose **Titan Embedding Model v2**\n",
    "\n",
    "- For Vector Store, we will keep the default choice to **Open Search Serverless**\n",
    "\n",
    "- We would also be required to have an intermidiatery s3 location to drop extracted images from multimodal files so those can be refrenced at teh generation time as shown below.\n",
    "\n",
    "![images/kb/kb_embedding.png](images/kb/kb_embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5dcdfe-fa29-47d9-bca4-c26ff9dcadbb",
   "metadata": {},
   "source": [
    "**Step 6: Review and Create the Knowledge Base**\n",
    "\n",
    "Finally, lets review the details enter, and click submit to create a Multimodal Knowledge base\n",
    "\n",
    "Once the Knowledge base is created (this generally takes 4-5 mins) you would see the following message on screen\n",
    "\n",
    "![images/kb/kb_successmsg.png](images/kb/kb_successmsg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d2a8a-9486-4ea7-99fe-7f91ea9dcb65",
   "metadata": {},
   "source": [
    "### This overall process takes roughly 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de59cc3-0058-495b-9816-95339381baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb29b99-f31e-420e-8c9a-b1b166d04e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pprint\n",
    "import random\n",
    "import time\n",
    "from retrying import retry\n",
    "\n",
    "boto3_session = boto3.session.Session(region_name='us-west-2')\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a60e8-e3f1-4ebe-acdb-4df134c1381e",
   "metadata": {},
   "source": [
    "### Ignore any pip install dependency errors you may witness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e3543e-e2b8-4d98-b5f4-2ab427fbada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.15 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires fsspec<=2024.10.0,>=2023.6.0, but you have fsspec 2025.2.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -q -r requirements.txt  --ignore-installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e233c3-20eb-46f4-a04f-c4ca617d551a",
   "metadata": {},
   "source": [
    "### 2. Key Information\n",
    "\n",
    "Once the Knowledge Base is created lets note down the following key information in below cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa90b0-78e5-4ce9-8373-0a782c91bc8d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please make sure to add Knowledge Base Name, Id, Data Source ID and the IAM role name created below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919fa27c-a08c-429a-a846-3aa2d5a7a6c5",
   "metadata": {},
   "source": [
    "![images/kb/kb_id_iam_role.png](images/kb/kb_id_iam_role.png)\n",
    "\n",
    "![images/kb/ds_id.png](images/kb/ds_id.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb521d0-d4b2-418c-9279-4d93690dfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ⚠️ ⚠️ replace below values with the created knowledge base and data source\n",
    "kb_name = \"knowledge-base-quick-start-ruiliang\"\n",
    "kb_id = \"0P698YVCTM\"\n",
    "ds_id = \"VLWEBP7VAT\"\n",
    "kb_iam_role_name = \"AmazonBedrockExecutionRoleForKnowledgeBase_v24y2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3bc1b8a-436d-465b-ba78-17310a6e0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_region_name='us-west-2'\n",
    "nova_reigon_name = 'us-east-1'\n",
    "\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', \n",
    "                                            region_name=kb_region_name)\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime', \n",
    "                                            region_name=kb_region_name)\n",
    "\n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb_id)\n",
    "\n",
    "get_ds_response = bedrock_agent_client.get_data_source(knowledgeBaseId = kb_id, dataSourceId = ds_id)\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79450cb-52dd-4d0b-b586-01886c7334d4",
   "metadata": {},
   "source": [
    "### 3. Ingest the Hotel Information Files into the S3 location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91aa180-0e5b-4c91-bd11-d44ada883d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_sleep(seconds: int):\n",
    "    dots = ''\n",
    "    for i in range(seconds):\n",
    "        dots += '.'\n",
    "        print(dots, end='\\r')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1b815-1201-4df7-8f5c-7af1e0488470",
   "metadata": {},
   "source": [
    "### We will use 2 S3 buckets \n",
    "1. **Data Source Input S3 Bucket**: This s3 bucket will serve as an input for creating our Data Source which will create a Vector Database using OpenSearch Serverless. For this we will use the pre-created bucket of the format\n",
    "`mmu-workshop-<ACCOUNT_ID>-*****`\n",
    "\n",
    "2. **Multimodal Storage Bucket**: This s3 bucket will be used to write and read any extracted images from multimodal documents that needs to be refrenced while answering questions related to images. For this we will use a pre-created bucket of the format\n",
    "`mmu-workshop-tmp-<ACCOUNT_ID>-*****`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931f290-48b6-490e-9fba-e226e3ea6b1b",
   "metadata": {},
   "source": [
    "**Note**: We will be syncing in \"mm-data\" partition, if you are syncing somewhere else please make the appropriate modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48e9c6f-09e1-4be2-9059-420738d4e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to s3 to the bucket that was configured as a data source to the knowledge bas\n",
    "\n",
    "bucket_name = \"sagemaker-us-west-2-710299592439\"\n",
    "s3_path = \"genai/knowledge-base-source-data\"\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name=kb_region_name)\n",
    "def uploadDirectory(path, bucket_name, s3_path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            s3_key = os.path.join(s3_path, os.path.relpath(local_file_path, path))\n",
    "            # Upload the file with the new S3 key\n",
    "            s3_client.upload_file(local_file_path, bucket_name, s3_key)\n",
    "\n",
    "uploadDirectory('kb_data', bucket_name, s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048f950-fa9d-4c93-9a66-f75665582699",
   "metadata": {},
   "source": [
    "### 4. Sync the KB Data Source _[You can also skip this to do from UI by clicking \"Sync Data Source\"]_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455e82a-ded8-48cd-a3af-2ee37c290916",
   "metadata": {},
   "source": [
    "![images/kb/kb_sync.png](images/kb/kb_sync.png)\n",
    "\n",
    "This may take 5-7 mins to sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f5ab9f-2f88-4f03-99d7-a8c63b59a99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion job started successfully\n",
      "\n",
      "{ 'dataSourceId': 'VLWEBP7VAT',\n",
      "  'ingestionJobId': 'YKMHCKG1TK',\n",
      "  'knowledgeBaseId': '0P698YVCTM',\n",
      "  'startedAt': datetime.datetime(2025, 2, 7, 10, 6, 4, 486189, tzinfo=tzlocal()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 3,\n",
      "                  'numberOfMetadataDocumentsModified': 0,\n",
      "                  'numberOfMetadataDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 3},\n",
      "  'status': 'COMPLETE',\n",
      "  'updatedAt': datetime.datetime(2025, 2, 7, 10, 6, 31, 603795, tzinfo=tzlocal())}\n",
      "........................................\r"
     ]
    }
   ],
   "source": [
    "interactive_sleep(30)\n",
    "ingest_jobs=[]\n",
    "# Start an ingestion job\n",
    "try:\n",
    "    start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb_id, dataSourceId = ds_id)\n",
    "    job = start_job_response[\"ingestionJob\"]\n",
    "    job_id = job[\"ingestionJobId\"]\n",
    "    print(f\"Ingestion job started successfully\\n\")\n",
    "\n",
    "    while job['status'] not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "        get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "          knowledgeBaseId = kb_id,\n",
    "            dataSourceId = ds_id,\n",
    "            ingestionJobId = job_id\n",
    "      )\n",
    "        job = get_job_response[\"ingestionJob\"]\n",
    "    pp.pprint(job)\n",
    "    interactive_sleep(40)\n",
    "    ingest_jobs.append(job)\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't start job.\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa111d-d190-46b0-af66-bcaded29c9b0",
   "metadata": {},
   "source": [
    "### 5. Update the IAM Policy to include Amazon Nova as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0064cfed-39b8-4920-a408-56443b4cc87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error attaching policy JSON to role: An error occurred (EntityAlreadyExists) when calling the CreatePolicy operation: A policy called NovaProModelPolicy2 already exists. Duplicate names are not allowed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attach_policy_json_to_role(role_name, policy_name, policy_json):\n",
    "    \"\"\"\n",
    "    Attaches a policy JSON directly to an IAM role.\n",
    "\n",
    "    :param role_name: The name of the IAM role\n",
    "    :param policy_name: The name to give the new policy\n",
    "    :param policy_json: The policy document as a JSON string or dictionary\n",
    "    :return: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an IAM client\n",
    "        iam_client = boto3.client('iam')\n",
    "\n",
    "        # Ensure policy_json is a string\n",
    "        if isinstance(policy_json, dict):\n",
    "            policy_json = json.dumps(policy_json)\n",
    "\n",
    "        # Create the policy\n",
    "        response = iam_client.create_policy(\n",
    "            PolicyName=policy_name,\n",
    "            PolicyDocument=policy_json\n",
    "        )\n",
    "\n",
    "        # Get the ARN of the newly created policy\n",
    "        policy_arn = response['Policy']['Arn']\n",
    "\n",
    "        # Attach the policy to the role\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=policy_arn\n",
    "        )\n",
    "\n",
    "        print(f\"Successfully created policy {policy_name} and attached it to role {role_name}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error attaching policy JSON to role: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "policy_name = \"NovaProModelPolicy2\"\n",
    "policy_json = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"BedrockInvokeModelStatement\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:{nova_reigon_name}::foundation-model/{PRO_MODEL_ID}\",\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "attach_policy_json_to_role(kb_iam_role_name, policy_name, policy_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d216b7-4fef-47ad-9efa-545f4a09a03c",
   "metadata": {},
   "source": [
    "### 6. Test the KB retrieve and retrieve and generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640549d-543a-42a5-b106-b20d436f2278",
   "metadata": {},
   "source": [
    "### Using RetrieveAndGenerate API\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee83cf64-19a5-4a32-82bd-c20b2bf30208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "\n",
    "def ask_bedrock_llm_with_knowledge_base(query: str, model_arn: str, kb_id: str) -> str:\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\n",
    "            'text': query\n",
    "        },\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': model_arn\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "## Function to print retrieved response\n",
    "def print_response(response):\n",
    "#structure 'retrievalResults': list of contents. Each list has ['ResponseMetadata', 'citations', 'output', 'sessionId']\n",
    "    generated_text = response[\"output\"][\"text\"]\n",
    "    ref_ref_location_lst=[]\n",
    "    ref_ref_location_lst.append({\"generated_text\":generated_text})\n",
    "    for num, chunk in enumerate(response['citations']):   \n",
    "        ref_locations=[]\n",
    "        for i, ref in enumerate (chunk['retrievedReferences']):\n",
    "            data_dict = {\"ref_location\": ref['location'], \n",
    "                        \"ref_metadata\": ref['metadata']['x-amz-bedrock-kb-source-uri']}\n",
    "            if 'x-amz-bedrock-kb-byte-content-source' in ref['metadata'].keys():\n",
    "                 data_dict[\"ref_image\"] = ref['metadata']['x-amz-bedrock-kb-byte-content-source']\n",
    "            ref_locations.append(data_dict)\n",
    "        ref_ref_location_lst.append({\"chunk_details\":ref_locations})\n",
    "    return ref_ref_location_lst\n",
    "\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import s3fs\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "\n",
    "def create_tree_widget(data, s3=None):\n",
    "    s3 = s3 or s3fs.S3FileSystem(anon=False)\n",
    "    main_accordion = widgets.Accordion()\n",
    "    \n",
    "    for i, item in enumerate(data):\n",
    "        subchildren = []\n",
    "        \n",
    "        # Always add Generated Text first\n",
    "        if 'generated_text' in item:\n",
    "            text_widget = widgets.Textarea(\n",
    "                value=str(item['generated_text']),\n",
    "                disabled=True,\n",
    "                layout=widgets.Layout(width='500px', height='200px')\n",
    "            )\n",
    "            subchildren.append(text_widget)\n",
    "        \n",
    "        # Then add Chunk Details\n",
    "        if 'chunk_details' in item:\n",
    "            chunk_accordion = widgets.Accordion()\n",
    "            chunk_children = []\n",
    "            \n",
    "            for chunk in item['chunk_details']:\n",
    "                chunk_subchildren = []\n",
    "                \n",
    "                for key, value in chunk.items():\n",
    "                    if key == 'ref_image' and isinstance(value, str) and value.startswith('s3://'):\n",
    "                        try:\n",
    "                            with s3.open(value, 'rb') as f:\n",
    "                                img = PILImage.open(f).resize((400, 400))\n",
    "                                img_byte_arr = io.BytesIO()\n",
    "                                img.save(img_byte_arr, format='PNG')\n",
    "                                img_widget = widgets.Image(\n",
    "                                    value=img_byte_arr.getvalue(),\n",
    "                                    format='png',\n",
    "                                    width=400,\n",
    "                                    height=400\n",
    "                                )\n",
    "                            chunk_subchildren.append(img_widget)\n",
    "                        except Exception as e:\n",
    "                            chunk_subchildren.append(widgets.Label(f\"Image Error: {e}\"))\n",
    "                    else:\n",
    "                        chunk_subchildren.append(widgets.Label(f\"{key}: {json.dumps(value)}\"))\n",
    "                \n",
    "                chunk_item_accordion = widgets.Accordion(children=tuple(chunk_subchildren))\n",
    "                for k, child in enumerate(chunk_subchildren):\n",
    "                    chunk_item_accordion.set_title(k, list(chunk.keys())[k])\n",
    "                \n",
    "                chunk_children.append(chunk_item_accordion)\n",
    "            \n",
    "            chunk_accordion = widgets.Accordion(children=tuple(chunk_children))\n",
    "            for j, child in enumerate(chunk_children):\n",
    "                chunk_accordion.set_title(j, f'Chunk {j+1}')\n",
    "            \n",
    "            subchildren.append(chunk_accordion)\n",
    "        \n",
    "        # Create item accordion with correct titles\n",
    "        item_accordion = widgets.Accordion(children=tuple(subchildren))\n",
    "        item_accordion.set_title(0, 'Generated Text')\n",
    "        if len(subchildren) > 1:\n",
    "            item_accordion.set_title(1, 'Chunk Details')\n",
    "        \n",
    "        main_accordion.children += (item_accordion,)\n",
    "        main_accordion.set_title(i, f'Item {i}')\n",
    "    \n",
    "    return main_accordion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ee551-a1a7-457c-a96e-689fc7f4a152",
   "metadata": {},
   "source": [
    "### Using Textual Information Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "584e18ae-ee63-4946-acf5-1508b5618258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93f6e728b4241759e9b294f0980567c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Accordion(children=(Textarea(value='The check-in time at ABC Grand hotel is 3:00 PM, and t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is the check-in and check-out time at ABC Grand hotel?\"\n",
    "cross_region_inference = True\n",
    "\n",
    "if cross_region_inference == True:\n",
    "    model_arn = f'arn:aws:bedrock:{kb_region_name}:{account_id}:inference-profile/us.{PRO_MODEL_ID}'\n",
    "else:\n",
    "    model_arn = f'arn:aws:bedrock:{nova_reigon_name}::foundation-model/{PRO_MODEL_ID}'\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "response_data = print_response(response)\n",
    "tree_widget = create_tree_widget(response_data)\n",
    "display(tree_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4fcde-a2a6-4333-b9e0-e74341e0cd78",
   "metadata": {},
   "source": [
    "### Using Multimodal search to find information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5320233b-4cf5-43e0-a962-1bcd48e8cef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f09b12210a4adf98b92c4f19d9f782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Accordion(children=(Textarea(value='The model cannot find sufficient information to answer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Is there a Fitness Room at ABC Grand? If so, where is it located ?\"\n",
    "\n",
    "cross_region_inference = True\n",
    "\n",
    "if cross_region_inference == True:\n",
    "    model_arn = f'arn:aws:bedrock:{kb_region_name}:{account_id}:inference-profile/us.{PRO_MODEL_ID}'\n",
    "else:\n",
    "    model_arn = f'arn:aws:bedrock:{nova_reigon_name}::foundation-model/{PRO_MODEL_ID}'\n",
    "    \n",
    "response = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "response_data = print_response(response)\n",
    "tree_widget = create_tree_widget(response_data)\n",
    "display(tree_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5a584-a844-4371-b493-648007a74a71",
   "metadata": {},
   "source": [
    "### Chart and Graph Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bec4c95-bbb7-44b9-b54d-9063714a58b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa1456e9ab6453f9d40dbaf6e7a6f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Accordion(children=(Textarea(value='The revenue in 2023 was 558.1 million USD, which is an…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is the revenue in 2022 versus 2023?\"\n",
    "cross_region_inference = True\n",
    "\n",
    "if cross_region_inference == True:\n",
    "    model_arn = f'arn:aws:bedrock:{kb_region_name}:{account_id}:inference-profile/us.{PRO_MODEL_ID}'\n",
    "else:\n",
    "    model_arn = f'arn:aws:bedrock:{nova_reigon_name}::foundation-model/{PRO_MODEL_ID}'\n",
    "\n",
    "response = ask_bedrock_llm_with_knowledge_base(query, model_arn, kb_id)\n",
    "response_data = print_response(response)\n",
    "tree_widget = create_tree_widget(response_data)\n",
    "display(tree_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06753f27-d431-4579-9794-16ddb03e6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store kb_name\n",
    "%store kb_id\n",
    "%store ds_id\n",
    "%store account_id\n",
    "%store bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e16d0-328a-4af1-97b2-5d60a9f6e99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
